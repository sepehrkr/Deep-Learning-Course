{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30646,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "!pip install adapters peft"
      ],
      "metadata": {
        "id": "ZE9gGsW050BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertConfig, BertModel, AdamW, get_constant_schedule_with_warmup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from adapters import AdapterCompositionBlock, AdapterConfig, UniPELTConfig, AutoAdapterModel\n",
        "from torchmetrics.functional import f1_score, accuracy\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from peft import LoraConfig, get_peft_model, TaskType"
      ],
      "metadata": {
        "id": "5CRf3OdcabGl",
        "execution": {
          "iopub.status.busy": "2024-02-02T21:55:22.921861Z",
          "iopub.execute_input": "2024-02-02T21:55:22.922221Z",
          "iopub.status.idle": "2024-02-02T21:55:30.756441Z",
          "shell.execute_reply.started": "2024-02-02T21:55:22.922193Z",
          "shell.execute_reply": "2024-02-02T21:55:30.755635Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "trusted": true,
        "id": "woDdMcsE5nxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "gdown.download(\"https://drive.google.com/file/d/1k5LMwmYF7PF-BzYQNE2ULBae79nbM268/view?usp=drive_link\", \"subtaskB_train.jsonl\", quiet=False, fuzzy=True)\n",
        "gdown.download(\"https://drive.google.com/file/d/1oh9c-d0fo3NtETNySmCNLUc6H1j4dSWE/view?usp=drive_link\", \"subtaskB_dev.jsonl\", quiet=False, fuzzy=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T15:06:47.743313Z",
          "iopub.execute_input": "2024-02-02T15:06:47.744331Z",
          "iopub.status.idle": "2024-02-02T15:06:54.287098Z",
          "shell.execute_reply.started": "2024-02-02T15:06:47.744290Z",
          "shell.execute_reply": "2024-02-02T15:06:54.286018Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "flr756gs5nxE",
        "outputId": "b5151eb2-2722-4870-f59f-12405c9b0243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1k5LMwmYF7PF-BzYQNE2ULBae79nbM268\n",
            "From (redirected): https://drive.google.com/uc?id=1k5LMwmYF7PF-BzYQNE2ULBae79nbM268&confirm=t&uuid=fa96b154-3ffa-47d4-8e7c-e4b6c4a864a6\n",
            "To: /content/subtaskB_train.jsonl\n",
            "100%|██████████| 155M/155M [00:05<00:00, 30.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1oh9c-d0fo3NtETNySmCNLUc6H1j4dSWE\n",
            "To: /content/subtaskB_dev.jsonl\n",
            "100%|██████████| 4.93M/4.93M [00:00<00:00, 94.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'subtaskB_dev.jsonl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameters"
      ],
      "metadata": {
        "id": "jHC2tIpJabGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "max_length = 128\n",
        "epoch_nums = 5\n",
        "lr = 1e-4\n",
        "epsilon = 1e-8\n",
        "splits = [0.01, 0.05, 0.1, 0.5]\n",
        "\n",
        "train_path = 'subtaskB_train.jsonl'\n",
        "val_path = 'subtaskB_dev.jsonl'\n",
        "\n",
        "discriminator_save_path = 'discriminator.pth'\n",
        "bert_save_path = 'bert.pth'\n",
        "report_path = 'report_Bert_adapter.csv'"
      ],
      "metadata": {
        "id": "cnf-N9TjabGo",
        "execution": {
          "iopub.status.busy": "2024-02-02T21:55:37.760872Z",
          "iopub.execute_input": "2024-02-02T21:55:37.761436Z",
          "iopub.status.idle": "2024-02-02T21:55:37.814641Z",
          "shell.execute_reply.started": "2024-02-02T21:55:37.761404Z",
          "shell.execute_reply": "2024-02-02T21:55:37.813609Z"
        },
        "trusted": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "nb_ACjyjabGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_json(train_path,lines=True)\n",
        "val_data = pd.read_json(val_path, lines=True)\n",
        "\n",
        "label_dict = {'chatGPT':0, 'human':1, 'cohere':2, 'davinci':3, 'bloomz':4, 'dolly':5}\n",
        "label2int = lambda label: label_dict[label]\n",
        "\n",
        "train_text = list(train_data['text'])\n",
        "label_train = list(train_data['model'].apply(label2int))\n",
        "text_val= list(val_data['text'])\n",
        "label_val = list(val_data['model'].apply(label2int))"
      ],
      "metadata": {
        "id": "jN2JnUg7abGo",
        "execution": {
          "iopub.status.busy": "2024-02-02T21:55:41.080505Z",
          "iopub.execute_input": "2024-02-02T21:55:41.081412Z",
          "iopub.status.idle": "2024-02-02T21:55:42.600972Z",
          "shell.execute_reply.started": "2024-02-02T21:55:41.081372Z",
          "shell.execute_reply": "2024-02-02T21:55:42.600128Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "splits = [0.01, 0.05, 0.1, 0.5]\n",
        "train_datasets = []\n",
        "for split in splits:\n",
        "    labeled_text, _, label, _  = train_test_split(train_text,label_train,test_size=1-split)\n",
        "    label = torch.LongTensor(label)\n",
        "    tokenized_labeled_text = tokenizer(labeled_text, max_length=max_length, truncation=True, padding='max_length',return_tensors='pt')\n",
        "\n",
        "    tokenized_text = {'input_ids':tokenized_labeled_text['input_ids'],\n",
        "                      'attention_mask': tokenized_labeled_text['attention_mask'],\n",
        "                      'label': label}\n",
        "\n",
        "    train_dataset = TensorDataset(tokenized_text['input_ids'],tokenized_text['attention_mask'], tokenized_text['label'])\n",
        "    train_datasets.append(train_dataset)\n",
        "    print(f\"train dataset for split {split} added.\")\n",
        "\n",
        "with open('train_datasets.pkl','wb') as f:\n",
        "     pickle.dump(train_datasets,f)\n",
        "\n",
        "tokenized_text = tokenizer(text_val, max_length=max_length, truncation=True, padding='max_length',return_tensors='pt')\n",
        "val_dataset = TensorDataset(tokenized_text['input_ids'], tokenized_text['attention_mask'], torch.LongTensor(label_val))\n",
        "with open('val_dataset.pkl','wb') as f:\n",
        "     pickle.dump(val_dataset,f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T16:37:53.957143Z",
          "iopub.status.idle": "2024-02-02T16:37:53.958204Z",
          "shell.execute_reply.started": "2024-02-02T16:37:53.957956Z",
          "shell.execute_reply": "2024-02-02T16:37:53.957975Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aRMkuSY5nxG",
        "outputId": "12321328-a94a-4918-9ae7-602281313bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train dataset for split 0.01 added.\n",
            "train dataset for split 0.05 added.\n",
            "train dataset for split 0.1 added.\n",
            "train dataset for split 0.5 added.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_b0MCS59zYg",
        "outputId": "48961184-a582-46ea-b3ba-4a93dad2f030"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/train_datasets.pkl','rb') as f:\n",
        "    train_datasets = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/val_dataset.pkl','rb') as f:\n",
        "    val_dataset = pickle.load(f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T21:55:45.962876Z",
          "iopub.execute_input": "2024-02-02T21:55:45.963596Z",
          "iopub.status.idle": "2024-02-02T21:55:47.680513Z",
          "shell.execute_reply.started": "2024-02-02T21:55:45.963564Z",
          "shell.execute_reply": "2024-02-02T21:55:47.679720Z"
        },
        "trusted": true,
        "id": "XCZlbL035nxH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainLoaders = []\n",
        "for train_dataset in train_datasets:\n",
        "    trainLoaders.append(DataLoader(train_dataset,batch_size=batch_size,shuffle=True))\n",
        "\n",
        "valLoader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "Jm-UYZjPabGp",
        "execution": {
          "iopub.status.busy": "2024-02-02T21:55:51.503624Z",
          "iopub.execute_input": "2024-02-02T21:55:51.503977Z",
          "iopub.status.idle": "2024-02-02T21:55:51.509540Z",
          "shell.execute_reply.started": "2024-02-02T21:55:51.503950Z",
          "shell.execute_reply": "2024-02-02T21:55:51.508378Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "ahQZLD-uabGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.feat = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(768,768), nn.LeakyReLU(), nn.Dropout(p=0.2))\n",
        "        self.logit = nn.Linear(768,6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat = self.feat(x)\n",
        "        logit = self.logit(feat)\n",
        "        return feat, logit\n",
        "\n",
        "class Bert(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        lora_config = LoraConfig(\n",
        "        task_type=TaskType.FEATURE_EXTRACTION, # this is necessary\n",
        "        )\n",
        "\n",
        "        # add LoRA adaptor\n",
        "        self.model = get_peft_model(self.model, lora_config)\n",
        "\n",
        "    def forward(self, input_ids, att_mask):\n",
        "        return self.model(input_ids, att_mask)[0][:,0,:]"
      ],
      "metadata": {
        "id": "jXobehoRabGp",
        "execution": {
          "iopub.status.busy": "2024-02-02T21:57:00.054243Z",
          "iopub.execute_input": "2024-02-02T21:57:00.054961Z",
          "iopub.status.idle": "2024-02-02T21:57:00.064289Z",
          "shell.execute_reply.started": "2024-02-02T21:57:00.054930Z",
          "shell.execute_reply": "2024-02-02T21:57:00.063338Z"
        },
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Validation"
      ],
      "metadata": {
        "id": "pjB_MTKAabGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(bert, discriminator, valLoader):\n",
        "    with torch.no_grad():\n",
        "        bert.eval()\n",
        "        discriminator.eval()\n",
        "        all_prediction = []\n",
        "        all_targets = []\n",
        "        for i, batch in tqdm(enumerate(valLoader), total=len(valLoader), desc=f'Validation'):\n",
        "\n",
        "            input_ids = batch[0].cuda()\n",
        "            att_mask = batch[1].cuda()\n",
        "            targets = batch[2].cuda()\n",
        "\n",
        "            y_bert = bert(input_ids, att_mask)\n",
        "            logits = discriminator(y_bert)[1]\n",
        "\n",
        "            preds = logits.max(dim=-1)[1]\n",
        "            all_prediction.append(preds.cpu())\n",
        "            all_targets.append(targets.cpu())\n",
        "\n",
        "\n",
        "    return f1_score(preds, targets, 'multiclass', num_classes=6), accuracy(preds, targets, 'multiclass', num_classes=6)"
      ],
      "metadata": {
        "id": "Z9BuWvleabGq",
        "execution": {
          "iopub.status.busy": "2024-02-02T21:57:04.528845Z",
          "iopub.execute_input": "2024-02-02T21:57:04.529209Z",
          "iopub.status.idle": "2024-02-02T21:57:04.537003Z",
          "shell.execute_reply.started": "2024-02-02T21:57:04.529180Z",
          "shell.execute_reply": "2024-02-02T21:57:04.536033Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#bert = torch.nn.parallel.DataParallel(bert, device_ids=list(range(2)), dim=0)\n",
        "#generator = torch.nn.parallel.DataParallel(generator, device_ids=list(range(2)), dim=0)\n",
        "#discriminator = torch.nn.parallel.DataParallel(discriminator, device_ids=list(range(2)), dim=0)\n",
        "\n",
        "\n",
        "\n",
        "f1s = []\n",
        "accs = []\n",
        "\n",
        "for split, trainLoader in zip(splits,trainLoaders):\n",
        "    discriminator = Discriminator().cuda()\n",
        "    bert = Bert().cuda()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "    optimizer = AdamW(list(discriminator.parameters()) + list(bert.parameters()), lr=lr)\n",
        "\n",
        "    num_train_steps = int(len(trainLoader) * epoch_nums)\n",
        "    num_warmup_steps = int(num_train_steps * 0.1)\n",
        "    scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps)\n",
        "\n",
        "    for epoch in range(epoch_nums):\n",
        "        discriminator.train()\n",
        "        bert.train()\n",
        "\n",
        "        current_loss = 0.0\n",
        "        for i, batch in tqdm(enumerate(trainLoader), total=len(trainLoader), desc=f'({split}) epoch {epoch}'):\n",
        "\n",
        "            input_ids = batch[0].cuda()\n",
        "            att_mask = batch[1].cuda()\n",
        "            targets = batch[2].cuda()\n",
        "\n",
        "            y_bert = bert(input_ids, att_mask)\n",
        "            logits = discriminator(y_bert)[1]\n",
        "\n",
        "            loss = criterion(logits, targets)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            current_loss += loss.item()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "        print(f'Loss: {current_loss / len(trainLoader)}')\n",
        "        f1, acc = validation(bert, discriminator, valLoader)\n",
        "        print(f'f1 score: {f1.item()}, accuracy: {acc.item()}')\n",
        "\n",
        "        torch.save(discriminator.state_dict(), f'split_{split}_'+discriminator_save_path)\n",
        "        torch.save(bert.state_dict(), f'split_{split}_'+bert_save_path)\n",
        "\n",
        "    f1s.append(f1.item())\n",
        "    accs.append(acc.item())\n",
        "\n",
        "report = pd.DataFrame({\"splits\": splits, \"accuracies\": accs, \"f1 score\": f1s})\n",
        "report.to_csv(report_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX_cJ-6GabGr",
        "outputId": "1a83e0e1-2edc-4a04-fa20-8c848cbc078d",
        "execution": {
          "iopub.status.busy": "2024-02-02T21:57:07.961912Z",
          "iopub.execute_input": "2024-02-02T21:57:07.962542Z"
        },
        "trusted": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "(0.01) epoch 0: 100%|██████████| 23/23 [00:15<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.789930779000987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.2083333283662796, accuracy: 0.2083333283662796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.01) epoch 1: 100%|██████████| 23/23 [00:14<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.7446655086849048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:35<00:00,  2.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.375, accuracy: 0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.01) epoch 2: 100%|██████████| 23/23 [00:17<00:00,  1.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.6917161630547566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:33<00:00,  2.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.2916666567325592, accuracy: 0.2916666567325592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.01) epoch 3: 100%|██████████| 23/23 [00:16<00:00,  1.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.650471127551535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:37<00:00,  2.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.1666666716337204, accuracy: 0.1666666716337204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.01) epoch 4: 100%|██████████| 23/23 [00:14<00:00,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.5760386352953704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:37<00:00,  2.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.3333333432674408, accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "(0.05) epoch 0: 100%|██████████| 111/111 [01:21<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.7523448939795967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:29<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.375, accuracy: 0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.05) epoch 1: 100%|██████████| 111/111 [01:21<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.4928501479260556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:30<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.4583333432674408, accuracy: 0.4583333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.05) epoch 2: 100%|██████████| 111/111 [01:22<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.2009331788028683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:29<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.375, accuracy: 0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.05) epoch 3: 100%|██████████| 111/111 [01:20<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.0277780342746425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:30<00:00,  3.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.3333333432674408, accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.05) epoch 4: 100%|██████████| 111/111 [01:21<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.9049429641113625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:30<00:00,  3.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.375, accuracy: 0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "(0.1) epoch 0: 100%|██████████| 222/222 [02:44<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.6856546745643959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:31<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.3333333432674408, accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.1) epoch 1: 100%|██████████| 222/222 [02:41<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.1684740636799786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:28<00:00,  3.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.375, accuracy: 0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.1) epoch 2: 100%|██████████| 222/222 [02:44<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.9256818710683702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:30<00:00,  3.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.3333333432674408, accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.1) epoch 3: 100%|██████████| 222/222 [02:38<00:00,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.8022968336805567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:29<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.4166666567325592, accuracy: 0.4166666567325592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.1) epoch 4: 100%|██████████| 222/222 [02:40<00:00,  1.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.7387058537554096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:26<00:00,  3.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.4583333432674408, accuracy: 0.4583333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "(0.5) epoch 0: 100%|██████████| 1110/1110 [13:30<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.2501451225162625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:31<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.5, accuracy: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.5) epoch 1: 100%|██████████| 1110/1110 [13:33<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.711013347635398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:28<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.5833333134651184, accuracy: 0.5833333134651184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.5) epoch 2: 100%|██████████| 1110/1110 [13:24<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6163750424309894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:32<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.5416666865348816, accuracy: 0.5416666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.5) epoch 3: 100%|██████████| 1110/1110 [13:33<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.5702215953184677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:24<00:00,  3.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.5833333134651184, accuracy: 0.5833333134651184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(0.5) epoch 4: 100%|██████████| 1110/1110 [13:34<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.5282231621645592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:28<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.4166666567325592, accuracy: 0.4166666567325592\n"
          ]
        }
      ]
    }
  ]
}